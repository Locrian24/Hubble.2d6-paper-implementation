{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIKv_exN8EA3"
      },
      "source": [
        "# REMEMBER THESE NOTEBOOKS AREN'T SAVED TO GITHUB. MANUALLY DOWNLOAD THEM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMaqb2OooOXz"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaZ5UF2MoTfj",
        "outputId": "e46873f7-59f6-413f-b226-22e9031c3abf"
      },
      "source": [
        "!git clone https://github.com/Locrian24/seng474-term-project.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'seng474-term-project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GvI5bS_oZpT",
        "outputId": "833ed50f-6290-4a09-f4ec-0cb42063221f"
      },
      "source": [
        "!cd seng474-term-project/ && git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GWlFbEPofie"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/seng474-term-project')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsCkDE92ovMl"
      },
      "source": [
        "from encode_to_seq import Encode2Seq"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HGDfnyPoxdu"
      },
      "source": [
        "# Global variables rn for testing\n",
        "\n",
        "ANNOTATIONS = '/content/seng474-term-project/data/gvcf2seq.annotation_embeddings.csv'\n",
        "EMBEDDINGS = '/content/seng474-term-project/data/embeddings.txt'\n",
        "REF = '/content/seng474-term-project/data/ref.seq'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laWNZhUIo2Bl"
      },
      "source": [
        "VCF = '/content/seng474-term-project/step3/star_samples.vcf'\n",
        "LABELS = '/content/seng474-term-project/step3/labels.csv'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcVVyrq6uMF_"
      },
      "source": [
        "np.random.seed(1337)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bk8Rn7ipC5I"
      },
      "source": [
        "encoding = Encode2Seq(vcf=VCF, labels=LABELS, label_cols=[0, 1, 2], embedding_file=EMBEDDINGS, annotation_file=ANNOTATIONS, ref_seq=REF)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfQ9jyQMp_ca"
      },
      "source": [
        "mask = np.all(np.isnan(encoding.y) == False, axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJ7rTsyHkXa"
      },
      "source": [
        "sample_y = encoding.y[mask]\n",
        "sample_X = encoding.X[mask.reshape(-1, 1).any(axis=1)]\n",
        "sample_names = encoding.sample_names[mask]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzIJzGV8s8G3"
      },
      "source": [
        "# Get valid stars\n",
        "all_stars = np.array([s.split('_')[1] for s in sample_names])\n",
        "stars, idx = np.unique(all_stars, return_index=True)\n",
        "\n",
        "# Choose which stars are training and which are test: (31, 24) split\n",
        "# Should be stratified with labels\n",
        "train_idx, test_idx = train_test_split(idx, stratify=sample_y[idx], test_size=0.43)\n",
        "\n",
        "# Retrieve indices of training and test stars\n",
        "sample_mask = np.isin(all_stars, all_stars[train_idx])\n",
        "\n",
        "# Split the data into the two sets\n",
        "_train_X, test_X = sample_X[sample_mask], sample_X[~sample_mask]\n",
        "_train_y, test_y = sample_y[sample_mask], sample_y[~sample_mask]\n",
        "\n",
        "uncurated_X = encoding.X[(~mask).reshape(-1, 1).any(axis=1)]\n",
        "uncurated_samples = encoding.sample_names[~mask]\n",
        "\n",
        "# Split training into train + validation (10% split -> validation)\n",
        "train_X, val_X, train_y, val_y = train_test_split(_train_X, _train_y, stratify=_train_y, test_size=0.1, random_state=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xw-TBy3NweV"
      },
      "source": [
        "## Custom output layers to convert probabilities to sample label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w048QDhlPu5l"
      },
      "source": [
        "https://arxiv.org/pdf/1901.07884.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOevqpBmN1ck"
      },
      "source": [
        "class FunctionProbToLabelLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, label, **kwargs):\n",
        "    self.label = label\n",
        "    super(FunctionProbToLabelLayer, self).__init__(**kwargs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcKwYCgH6WN5"
      },
      "source": [
        "## Load and fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFFfrnMRMzDz",
        "outputId": "e01f2925-ec3d-4ec1-94d9-0e56fb1cec96"
      },
      "source": [
        "json_file = open('/content/seng474-term-project/step_1/model.json', 'r')\n",
        "loaded_model = json_file.read()\n",
        "model = tf.keras.models.model_from_json(loaded_model)\n",
        "model.load_weights('/content/seng474-term-project/step_1/weights.h5')\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 2970, 70)          17360     \n",
            "_________________________________________________________________\n",
            "batch_1 (BatchNormalization) (None, 2970, 70)          280       \n",
            "_________________________________________________________________\n",
            "relu_1 (ReLU)                (None, 2970, 70)          0         \n",
            "_________________________________________________________________\n",
            "maxpooling_1 (MaxPooling1D)  (None, 990, 70)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 196, 46)           35466     \n",
            "_________________________________________________________________\n",
            "batch_2 (BatchNormalization) (None, 196, 46)           184       \n",
            "_________________________________________________________________\n",
            "relu_2 (ReLU)                (None, 196, 46)           0         \n",
            "_________________________________________________________________\n",
            "maxpooling_2 (MaxPooling1D)  (None, 49, 46)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 9, 46)             14858     \n",
            "_________________________________________________________________\n",
            "batch_3 (BatchNormalization) (None, 9, 46)             184       \n",
            "_________________________________________________________________\n",
            "relu_3 (ReLU)                (None, 9, 46)             0         \n",
            "_________________________________________________________________\n",
            "maxpooling_3 (MaxPooling1D)  (None, 2, 46)             0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 92)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2976      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 71,473\n",
            "Trainable params: 71,149\n",
            "Non-trainable params: 324\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0ThYdOnNVDw",
        "outputId": "9dd2202d-d6e8-4899-865c-eb5e434d0dd1"
      },
      "source": [
        "model.pop()\n",
        "model.pop()\n",
        "model.pop()\n",
        "model.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 2970, 70)          17360     \n",
            "_________________________________________________________________\n",
            "batch_1 (BatchNormalization) (None, 2970, 70)          280       \n",
            "_________________________________________________________________\n",
            "relu_1 (ReLU)                (None, 2970, 70)          0         \n",
            "_________________________________________________________________\n",
            "maxpooling_1 (MaxPooling1D)  (None, 990, 70)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 196, 46)           35466     \n",
            "_________________________________________________________________\n",
            "batch_2 (BatchNormalization) (None, 196, 46)           184       \n",
            "_________________________________________________________________\n",
            "relu_2 (ReLU)                (None, 196, 46)           0         \n",
            "_________________________________________________________________\n",
            "maxpooling_2 (MaxPooling1D)  (None, 49, 46)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 9, 46)             14858     \n",
            "_________________________________________________________________\n",
            "batch_3 (BatchNormalization) (None, 9, 46)             184       \n",
            "_________________________________________________________________\n",
            "relu_3 (ReLU)                (None, 9, 46)             0         \n",
            "_________________________________________________________________\n",
            "maxpooling_3 (MaxPooling1D)  (None, 2, 46)             0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 92)                0         \n",
            "=================================================================\n",
            "Total params: 68,332\n",
            "Trainable params: 0\n",
            "Non-trainable params: 68,332\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPaVa8a39TM_",
        "outputId": "a44027b1-7a40-44fa-fae9-0f65e43591ee"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(14868, 13))\n",
        "x = model(inputs, training=False)\n",
        "x = tf.keras.layers.Dense(32, activation=tf.keras.activations.relu, kernel_initializer=tf.keras.initializers.VarianceScaling(mode='fan_avg', distribution='uniform'), name = \"dense_5\")(x)\n",
        "x = tf.keras.layers.Dropout(rate=0.03, name=\"dropout_4\")(x)\n",
        "x = tf.keras.layers.Dense(1, activation=tf.keras.activations.linear, kernel_initializer=tf.keras.initializers.VarianceScaling(mode='fan_avg', distribution='uniform'), name = \"dense_6\")(x)\n",
        "outputs = tf.keras.layers.Dense(2, activation=tf.keras.activations.sigmoid, kernel_initializer=tf.keras.initializers.VarianceScaling(mode='fan_avg', distribution='uniform'), name = \"final_dense\")(x)\n",
        "\n",
        "final_model = tf.keras.Model(inputs, outputs)\n",
        "final_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 14868, 13)]       0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 92)                68332     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2976      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "_________________________________________________________________\n",
            "final_dense (Dense)          (None, 2)                 4         \n",
            "=================================================================\n",
            "Total params: 71,345\n",
            "Trainable params: 3,013\n",
            "Non-trainable params: 68,332\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVvZMWhiEuiv"
      },
      "source": [
        "_train_ds = tf.data.Dataset.from_tensor_slices((train_X, train_y))\n",
        "train_ds = _train_ds.cache().shuffle(32).batch(32).prefetch(buffer_size=10)\n",
        "\n",
        "_val_ds = tf.data.Dataset.from_tensor_slices((val_X, val_y))\n",
        "val_ds = _val_ds.cache().shuffle(32).batch(32).prefetch(buffer_size=10)\n",
        "\n",
        "_test_ds = tf.data.Dataset.from_tensor_slices((test_X, test_y))\n",
        "_test_ds = _test_ds.cache().prefetch(buffer_size=10)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1z75PoYEPkm",
        "outputId": "56818188-75b0-4646-b15e-ce64ee53350c"
      },
      "source": [
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "epochs = 20\n",
        "final_model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 159ms/step - loss: 0.6612 - binary_accuracy: 0.5528 - val_loss: 0.4865 - val_binary_accuracy: 0.5625\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.5078 - binary_accuracy: 0.6373 - val_loss: 0.5151 - val_binary_accuracy: 0.7188\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.5037 - binary_accuracy: 0.8134 - val_loss: 0.4445 - val_binary_accuracy: 0.8125\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4184 - binary_accuracy: 0.8345 - val_loss: 0.4220 - val_binary_accuracy: 0.8750\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4015 - binary_accuracy: 0.8380 - val_loss: 0.4252 - val_binary_accuracy: 0.8125\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.3561 - binary_accuracy: 0.8768 - val_loss: 0.4125 - val_binary_accuracy: 0.8125\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.3423 - binary_accuracy: 0.8521 - val_loss: 0.3879 - val_binary_accuracy: 0.8125\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.3216 - binary_accuracy: 0.8662 - val_loss: 0.3502 - val_binary_accuracy: 0.8125\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.3060 - binary_accuracy: 0.8803 - val_loss: 0.3471 - val_binary_accuracy: 0.8125\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.2811 - binary_accuracy: 0.8873 - val_loss: 0.3503 - val_binary_accuracy: 0.7812\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.2842 - binary_accuracy: 0.8803 - val_loss: 0.3336 - val_binary_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.2760 - binary_accuracy: 0.8697 - val_loss: 0.3198 - val_binary_accuracy: 0.8125\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.2617 - binary_accuracy: 0.8944 - val_loss: 0.3120 - val_binary_accuracy: 0.8125\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.2573 - binary_accuracy: 0.8944 - val_loss: 0.3127 - val_binary_accuracy: 0.8438\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.2502 - binary_accuracy: 0.9085 - val_loss: 0.3228 - val_binary_accuracy: 0.7812\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.2443 - binary_accuracy: 0.8979 - val_loss: 0.3138 - val_binary_accuracy: 0.7812\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.2395 - binary_accuracy: 0.9049 - val_loss: 0.3367 - val_binary_accuracy: 0.8438\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.2360 - binary_accuracy: 0.8908 - val_loss: 0.3300 - val_binary_accuracy: 0.8125\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.2299 - binary_accuracy: 0.9155 - val_loss: 0.3205 - val_binary_accuracy: 0.8438\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.2228 - binary_accuracy: 0.9120 - val_loss: 0.3044 - val_binary_accuracy: 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fadb5386490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzRkWb19t6fa",
        "outputId": "ff8f007d-8f71-4ebb-a87e-5efbc86642b3"
      },
      "source": [
        "model.trainable = True\n",
        "final_model.compile(\n",
        "    tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "epochs = 7\n",
        "final_model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "5/5 [==============================] - 3s 358ms/step - loss: 0.2206 - binary_accuracy: 0.9120 - val_loss: 0.2869 - val_binary_accuracy: 0.8438\n",
            "Epoch 2/7\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.2242 - binary_accuracy: 0.8979 - val_loss: 0.2859 - val_binary_accuracy: 0.8750\n",
            "Epoch 3/7\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.2092 - binary_accuracy: 0.9155 - val_loss: 0.2837 - val_binary_accuracy: 0.8438\n",
            "Epoch 4/7\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.2149 - binary_accuracy: 0.9014 - val_loss: 0.2835 - val_binary_accuracy: 0.8438\n",
            "Epoch 5/7\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.2149 - binary_accuracy: 0.9155 - val_loss: 0.2798 - val_binary_accuracy: 0.8438\n",
            "Epoch 6/7\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.2164 - binary_accuracy: 0.9085 - val_loss: 0.2802 - val_binary_accuracy: 0.8438\n",
            "Epoch 7/7\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.2138 - binary_accuracy: 0.9120 - val_loss: 0.2820 - val_binary_accuracy: 0.8438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fadb5386b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJor-AW-sImV",
        "outputId": "54d3c77f-5e61-450d-89e5-a3036090b0d9"
      },
      "source": [
        "final_model.evaluate(test_X, test_y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 99ms/step - loss: 0.3210 - binary_accuracy: 0.8103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32100391387939453, 0.8103448152542114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4BpHKZosM6f"
      },
      "source": [
        "preds = final_model.predict(test_X)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSuZhG0ovaEO"
      },
      "source": [
        "def get_functions(pred):\n",
        "  cutpoint_1 = 0.4260022\n",
        "  cutpoint_2 = 0.7360413\n",
        "\n",
        "  cut1 = np.greater(pred[:, 0], [cutpoint_1])\n",
        "  cut2 = np.greater(pred[:, 1], [cutpoint_2])\n",
        "\n",
        "  functions = []\n",
        "  for i in range(pred.shape[0]):\n",
        "    if cut1[i] == True and cut2[i] == True:\n",
        "      functions.append(\"Normal\")\n",
        "    elif cut1[i] == True and cut2[i] == False:\n",
        "      functions.append(\"Decreased Function\")\n",
        "    else:\n",
        "      functions.append(\"No function\")\n",
        "\n",
        "  return np.array(functions)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL9FyktBu4Po"
      },
      "source": [
        "predictions = get_functions(preds)\n",
        "true_labels = get_functions(test_y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caz_vb0Rv_Qq",
        "outputId": "e005adb9-ea25-4642-9fa5-df8e898f1547"
      },
      "source": [
        "np.sum(predictions == true_labels) / len(true_labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8620689655172413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orC5H_ZFxoyq"
      },
      "source": [
        "_uncurated_predictions = final_model.predict(uncurated_X)\n",
        "uncurated_predictions = get_functions(_uncurated_predictions)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-qoI_Gwx7xr",
        "outputId": "c7814e34-cf17-4102-8c17-fbcda6845fbd"
      },
      "source": [
        "list(zip(uncurated_samples, uncurated_predictions))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CYP2D6_102_001', 'Decreased Function'),\n",
              " ('CYP2D6_102_vcf', 'Normal'),\n",
              " ('CYP2D6_103_001', 'Decreased Function'),\n",
              " ('CYP2D6_103_vcf', 'Normal'),\n",
              " ('CYP2D6_104_001', 'Decreased Function'),\n",
              " ('CYP2D6_104_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_105_001', 'No function'),\n",
              " ('CYP2D6_105_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_106_001', 'Decreased Function'),\n",
              " ('CYP2D6_106_002', 'Normal'),\n",
              " ('CYP2D6_106_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_107_001', 'Normal'),\n",
              " ('CYP2D6_107_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_108_001', 'Normal'),\n",
              " ('CYP2D6_108_vcf', 'Normal'),\n",
              " ('CYP2D6_109_001', 'Normal'),\n",
              " ('CYP2D6_109_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_110_001', 'Decreased Function'),\n",
              " ('CYP2D6_110_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_111_001', 'Decreased Function'),\n",
              " ('CYP2D6_111_002', 'Decreased Function'),\n",
              " ('CYP2D6_111_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_112_001', 'Normal'),\n",
              " ('CYP2D6_112_vcf', 'Normal'),\n",
              " ('CYP2D6_113_001', 'Decreased Function'),\n",
              " ('CYP2D6_113_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_115_001', 'Normal'),\n",
              " ('CYP2D6_115_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_116_001', 'Normal'),\n",
              " ('CYP2D6_116_vcf', 'Normal'),\n",
              " ('CYP2D6_117_001', 'Decreased Function'),\n",
              " ('CYP2D6_117_vcf', 'No function'),\n",
              " ('CYP2D6_118_001', 'Normal'),\n",
              " ('CYP2D6_118_vcf', 'Normal'),\n",
              " ('CYP2D6_119_001', 'Normal'),\n",
              " ('CYP2D6_119_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_120_001', 'Decreased Function'),\n",
              " ('CYP2D6_120_vcf', 'No function'),\n",
              " ('CYP2D6_121_001', 'Normal'),\n",
              " ('CYP2D6_121_vcf', 'Normal'),\n",
              " ('CYP2D6_122_001', 'Decreased Function'),\n",
              " ('CYP2D6_122_vcf', 'No function'),\n",
              " ('CYP2D6_123_001', 'Decreased Function'),\n",
              " ('CYP2D6_123_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_124_001', 'Decreased Function'),\n",
              " ('CYP2D6_124_vcf', 'No function'),\n",
              " ('CYP2D6_125_001', 'Normal'),\n",
              " ('CYP2D6_125_vcf', 'No function'),\n",
              " ('CYP2D6_126_001', 'Decreased Function'),\n",
              " ('CYP2D6_126_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_127_001', 'Normal'),\n",
              " ('CYP2D6_127_vcf', 'Normal'),\n",
              " ('CYP2D6_128_001', 'Decreased Function'),\n",
              " ('CYP2D6_128_vcf', 'No function'),\n",
              " ('CYP2D6_129_001', 'Decreased Function'),\n",
              " ('CYP2D6_129_vcf', 'No function'),\n",
              " ('CYP2D6_130_001', 'Decreased Function'),\n",
              " ('CYP2D6_130_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_131_001', 'Decreased Function'),\n",
              " ('CYP2D6_131_vcf', 'No function'),\n",
              " ('CYP2D6_132_001', 'Decreased Function'),\n",
              " ('CYP2D6_132_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_133_001', 'Normal'),\n",
              " ('CYP2D6_133_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_134_001', 'Decreased Function'),\n",
              " ('CYP2D6_134_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_135_001', 'Decreased Function'),\n",
              " ('CYP2D6_135_vcf', 'No function'),\n",
              " ('CYP2D6_136_001', 'No function'),\n",
              " ('CYP2D6_136_vcf', 'No function'),\n",
              " ('CYP2D6_137_001', 'Decreased Function'),\n",
              " ('CYP2D6_137_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_138_001', 'Decreased Function'),\n",
              " ('CYP2D6_138_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_139_001', 'Normal'),\n",
              " ('CYP2D6_139_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_22_001', 'No function'),\n",
              " ('CYP2D6_22_vcf', 'No function'),\n",
              " ('CYP2D6_23_001', 'Normal'),\n",
              " ('CYP2D6_23_vcf', 'Normal'),\n",
              " ('CYP2D6_24_001', 'Normal'),\n",
              " ('CYP2D6_24_vcf', 'Normal'),\n",
              " ('CYP2D6_25_001', 'Normal'),\n",
              " ('CYP2D6_25_vcf', 'Normal'),\n",
              " ('CYP2D6_26_001', 'Normal'),\n",
              " ('CYP2D6_26_vcf', 'Normal'),\n",
              " ('CYP2D6_28_001', 'Decreased Function'),\n",
              " ('CYP2D6_28_002', 'Decreased Function'),\n",
              " ('CYP2D6_28_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_30_001', 'Decreased Function'),\n",
              " ('CYP2D6_30_vcf', 'No function'),\n",
              " ('CYP2D6_32_001', 'Normal'),\n",
              " ('CYP2D6_32_vcf', 'Normal'),\n",
              " ('CYP2D6_37_001', 'Decreased Function'),\n",
              " ('CYP2D6_37_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_43_001', 'Decreased Function'),\n",
              " ('CYP2D6_43_002', 'Decreased Function'),\n",
              " ('CYP2D6_43_vcf', 'No function'),\n",
              " ('CYP2D6_52_001', 'Decreased Function'),\n",
              " ('CYP2D6_52_002', 'Decreased Function'),\n",
              " ('CYP2D6_52_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_58_001', 'Decreased Function'),\n",
              " ('CYP2D6_58_vcf', 'No function'),\n",
              " ('CYP2D6_64_001', 'Decreased Function'),\n",
              " ('CYP2D6_64_vcf', 'No function'),\n",
              " ('CYP2D6_65_001', 'Normal'),\n",
              " ('CYP2D6_65_vcf', 'No function'),\n",
              " ('CYP2D6_70_001', 'Decreased Function'),\n",
              " ('CYP2D6_70_vcf', 'No function'),\n",
              " ('CYP2D6_71_001', 'Normal'),\n",
              " ('CYP2D6_71_002', 'Normal'),\n",
              " ('CYP2D6_71_003', 'Normal'),\n",
              " ('CYP2D6_71_vcf', 'Normal'),\n",
              " ('CYP2D6_73_001', 'Decreased Function'),\n",
              " ('CYP2D6_73_vcf', 'No function'),\n",
              " ('CYP2D6_74_001', 'Decreased Function'),\n",
              " ('CYP2D6_74_vcf', 'No function'),\n",
              " ('CYP2D6_75_001', 'Normal'),\n",
              " ('CYP2D6_75_vcf', 'Normal'),\n",
              " ('CYP2D6_81_001', 'Normal'),\n",
              " ('CYP2D6_81_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_82_001', 'Normal'),\n",
              " ('CYP2D6_82_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_83_001', 'Normal'),\n",
              " ('CYP2D6_83_002', 'No function'),\n",
              " ('CYP2D6_83_003', 'No function'),\n",
              " ('CYP2D6_83_vcf', 'No function'),\n",
              " ('CYP2D6_85_001', 'Normal'),\n",
              " ('CYP2D6_85_vcf', 'No function'),\n",
              " ('CYP2D6_86_001', 'Normal'),\n",
              " ('CYP2D6_86_vcf', 'Normal'),\n",
              " ('CYP2D6_87_001', 'Normal'),\n",
              " ('CYP2D6_87_vcf', 'Normal'),\n",
              " ('CYP2D6_88_001', 'Decreased Function'),\n",
              " ('CYP2D6_88_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_89_001', 'Normal'),\n",
              " ('CYP2D6_89_vcf', 'Normal'),\n",
              " ('CYP2D6_90_001', 'Normal'),\n",
              " ('CYP2D6_90_vcf', 'Normal'),\n",
              " ('CYP2D6_91_001', 'Normal'),\n",
              " ('CYP2D6_91_vcf', 'Normal'),\n",
              " ('CYP2D6_93_001', 'Normal'),\n",
              " ('CYP2D6_93_vcf', 'Normal'),\n",
              " ('CYP2D6_94_001', 'Decreased Function'),\n",
              " ('CYP2D6_94_002', 'Decreased Function'),\n",
              " ('CYP2D6_94_vcf', 'No function'),\n",
              " ('CYP2D6_95_001', 'Normal'),\n",
              " ('CYP2D6_95_vcf', 'Decreased Function'),\n",
              " ('CYP2D6_97_001', 'Normal'),\n",
              " ('CYP2D6_97_vcf', 'Normal'),\n",
              " ('CYP2D6_98_001', 'Decreased Function'),\n",
              " ('CYP2D6_98_vcf', 'Decreased Function')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}